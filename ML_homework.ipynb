{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0j6/GsUWHvdXEMb7FSiZr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BatmarcNYU/dataScienceBootCamp/blob/main/ML_homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jm0nyWgxHl6x",
        "outputId": "5352fefb-13f5-4234-e516-94f3e3a7213c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15073.52504568 18052.82609652 17141.87156964 ... 17355.74617264\n",
            " 17171.29983574 17530.77859363]\n",
            "mae  10057.19848602559\n",
            "mse  14570.558482521576\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from io import StringIO\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option(\"display.max_columns\", 101)\n",
        "\n",
        "df = pd.read_csv('/content/employee.csv')\n",
        "\n",
        "# df.shape #(4277, 13)\n",
        "df = df.drop(columns=['id', 'timestamp', 'country'])\n",
        "df.loc[df['hours_per_week'].isna(), 'hours_per_week'] = df['hours_per_week'].median()\n",
        "df.loc[df['telecommute_days_per_week'].isna(), 'telecommute_days_per_week'] = df['telecommute_days_per_week'].median()\n",
        "df = df.dropna()\n",
        "\n",
        "# df['country'] = pd.Categorical(df['country'])\n",
        "# df['country_code'] = df['country'].cat.codes\n",
        "training_data = df.copy()\n",
        "for feat in ['is_manager', 'certifications']:\n",
        "  training_data[feat] = training_data[feat].replace(to_replace=['Yes'], value=1)\n",
        "  training_data[feat] = training_data[feat].replace(to_replace=['No'], value=1)\n",
        "countries = ['Slovenia', 'United States', 'Sweden', 'United Kingdom', 'Canada', 'New Zealand', 'Belgium', 'France', 'Australia', 'India', 'Denmark', 'Romania', 'Poland', 'Norway', 'Croatia', 'Netherlands', 'Hungary', 'Argentina', 'Costa Rica', 'Switzerland', 'Germany', 'Mexico', 'Ukraine', 'Spain', 'Czech Republic', 'Portugal', 'South Africa', 'Hong Kong', 'Russia', 'Ireland', 'Guernsey', 'Israel', 'Bulgaria', 'Uganda', 'Finland', 'Italy', 'Jersey', 'United Arab Emirates', 'Austria', 'Turkey', 'Bahrain', 'Greece', 'Colombia', 'Kenya', 'Peru', 'Saudi Arabia', 'Albania', 'Iceland', 'Guatemala', 'Belarus', 'Moldova', 'Puerto Rico', 'Brazil', 'Indonesia', 'Slovakia', 'Serbia and Montenegro', 'Singapore', 'Malta', 'Venezuela', 'Latvia', 'China', 'Ecuador', 'Pakistan', 'Vietnam', 'Bolivia', 'Paraguay', 'Thailand', 'Lithuania', 'Jordan', 'Macedonia', 'Malaysia', 'Luxembourg', 'Philippines', 'Syria', 'Ghana', 'Taiwan', 'Estonia', 'Uruguay']\n",
        "\n",
        "# for country in df['country']:\n",
        "#   training_data['country_code'] = training_data['country'].replace(to_replace=[country], value=countries.index(country))\n",
        "# training_data = training_data.drop(columns=['country'])\n",
        "categorical_feats = [feat for feat in training_data.columns if training_data[feat].dtype == 'object' and feat not in ['is_manager', 'certifications']]\n",
        "\n",
        "# x = training_data[categorical_feats]\n",
        "# x\n",
        "# training_data['country_code']\n",
        "# df['country_code'] = df['country'].astype(int)\n",
        "# training_data[['is_manager', 'certifications']]\n",
        "final_data = pd.get_dummies(training_data, columns=categorical_feats, drop_first=True, dtype=int)\n",
        "\n",
        "y = final_data['salary']\n",
        "X = final_data.drop(columns=['salary'])\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "num_cols = ['job_years','hours_per_week','telecommute_days_per_week']\n",
        "\n",
        "# before\n",
        "# mae  9406.270120188927\n",
        "# mse  12812.500292380955\n",
        "# Z-score method for numerical columns to remove outliers\n",
        "z_scores = (df[num_cols] - df[num_cols].mean()) / df[num_cols].std()\n",
        "outliers_zscore = df[(z_scores.abs() > 3).any(axis=1)]\n",
        "\n",
        "df = df.drop(outliers_zscore.index)\n",
        "# after\n",
        "# mae  8046.525820478533\n",
        "# mse  9405.74164031662\n",
        "# # IQR method\n",
        "# Q1 = df[num_cols].quantile(0.25)\n",
        "# Q3 = df[num_cols].quantile(0.75)\n",
        "# IQR = Q3 - Q1\n",
        "# outliers_iqr = df[((df[num_cols] < (Q1 - 1.5 * IQR)) | (df[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
        "\n",
        "# # Remove outliers from the DataFrame\n",
        "# df = df[~((df[num_cols] < (Q1 - 1.5 * IQR)) | (df[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
        "\n",
        "# after\n",
        "# mae  9767.047123321843\n",
        "# mse  13759.637455681834\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train[num_cols])\n",
        "X_train[num_cols] = scaler.transform(X_train[num_cols])\n",
        "\n",
        "reg=LinearRegression()\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "# reg.coef_\n",
        "# reg.intercept_\n",
        "\n",
        "mean_squared_error(y_train, reg.predict(X_train))/np.mean(y_train)\n",
        "\n",
        "y_pred = reg.predict(X_test)\n",
        "print(y_pred)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print('mae ', mae)\n",
        "\n",
        "mse = mean_squared_error(y_pred, y_test)/np.mean(y_test)\n",
        "print('mse ', mse)\n"
      ]
    }
  ]
}